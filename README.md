# ReskPoints

> **AI Metrics Monitoring & Cost Tracking System**

ReskPoints is a comprehensive platform for monitoring AI model performance, tracking costs, and managing incidents across multiple AI providers. Built with FastAPI, it provides real-time insights into your AI infrastructure with enterprise-grade monitoring capabilities.

## ğŸš€ Features

### âœ… **Core Monitoring**
- **Real-time AI Metrics**: Track latency, throughput, error rates, and custom metrics
- **Multi-provider Support**: OpenAI, Anthropic, Google, Azure, and custom endpoints
- **Anomaly Detection**: Statistical and ML-based detection with configurable thresholds
- **Health Monitoring**: Comprehensive health checks and system status

### âœ… **Cost Intelligence**
- **Token Tracking**: Detailed token usage and cost calculation per provider
- **Budget Management**: Set limits, alerts, and optimization recommendations
- **Cost Analytics**: Breakdown by user, project, model, and time period
- **Predictive Insights**: Cost forecasting based on usage patterns

### âœ… **Incident Management**
- **Automated Ticketing**: Auto-generate tickets from errors and anomalies
- **Causality Analysis**: Graph-based error relationship tracking
- **Workflow Management**: Configurable ticket workflows and escalation
- **Impact Analysis**: Understand error propagation and root causes

### âœ… **Enterprise Ready**
- **Scalable Architecture**: Microservices with TimescaleDB, ClickHouse, Redis
- **Security**: JWT authentication, RBAC, audit logging, data encryption
- **Observability**: Prometheus metrics, structured logging, distributed tracing
- **API-First**: Comprehensive REST API with interactive documentation

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Data Sources  â”‚    â”‚   ReskPoints    â”‚    â”‚   Monitoring    â”‚
â”‚                 â”‚    â”‚     Core        â”‚    â”‚    & Alerts     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â€¢ OpenAI APIs   â”‚â”€â”€â”€â”€â”¤ â€¢ FastAPI App   â”‚â”€â”€â”€â”€â”¤ â€¢ Prometheus    â”‚
â”‚ â€¢ Custom APIs   â”‚    â”‚ â€¢ Async Workers â”‚    â”‚ â€¢ Grafana       â”‚
â”‚ â€¢ Webhooks      â”‚    â”‚ â€¢ Business Logicâ”‚    â”‚ â€¢ Alert Manager â”‚
â”‚ â€¢ Direct SDKs   â”‚    â”‚ â€¢ Data Pipeline â”‚    â”‚ â€¢ Notifications â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Data Layer    â”‚
                    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                    â”‚ â€¢ PostgreSQL    â”‚
                    â”‚ â€¢ TimescaleDB   â”‚
                    â”‚ â€¢ ClickHouse    â”‚
                    â”‚ â€¢ Redis Cache   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites
- Python 3.11+
- Docker & Docker Compose (recommended)
- PostgreSQL, Redis (for production)

### Option 1: Docker Development (Recommended)
```bash
# Clone the repository
git clone https://github.com/Resk-Security/ReskPoints.git
cd ReskPoints

# Start full development stack
cd deployments/docker
docker-compose up

# Access services:
# â€¢ API: http://localhost:8000
# â€¢ API Docs: http://localhost:8000/docs
# â€¢ Prometheus: http://localhost:9090
# â€¢ Grafana: http://localhost:3000 (admin/admin)
```

### Option 2: Local Development
```bash
# Clone and setup
git clone https://github.com/Resk-Security/ReskPoints.git
cd ReskPoints

# Setup development environment
./scripts/setup-dev.sh

# Activate virtual environment
source venv/bin/activate

# Start development server
uvicorn reskpoints.main:create_app --reload --host 0.0.0.0 --port 8000
```

### Option 3: Production Deployment
```bash
# Build production image
docker build -f deployments/docker/Dockerfile --target production -t reskpoints:latest .

# Run with environment variables
docker run -p 8000:8000 \
  -e DATABASE_URL="postgresql://user:pass@host:5432/reskpoints" \
  -e REDIS_URL="redis://host:6379/0" \
  -e SECRET_KEY="your-secret-key-here" \
  reskpoints:latest
```

## ğŸ“Š API Usage Examples

### Submit AI Metrics
```bash
curl -X POST http://localhost:8000/api/v1/metrics/submit \
  -H "Content-Type: application/json" \
  -d '{
    "metric_type": "latency",
    "value": 150.5,
    "unit": "ms",
    "provider": "openai",
    "model_name": "gpt-3.5-turbo",
    "endpoint": "/v1/chat/completions",
    "user_id": "user_123",
    "project_id": "project_456",
    "metadata": {
      "region": "us-east-1",
      "environment": "production"
    }
  }'
```

### Track Costs & Token Usage
```bash
curl -X POST http://localhost:8000/api/v1/cost/transactions \
  -H "Content-Type: application/json" \
  -d '{
    "provider": "openai",
    "model_name": "gpt-3.5-turbo",
    "endpoint": "/v1/chat/completions",
    "user_id": "user_123",
    "project_id": "project_456",
    "success": true,
    "token_usage": {
      "input_tokens": 100,
      "output_tokens": 50,
      "total_tokens": 150
    },
    "cost_breakdown": {
      "input_cost": 0.001,
      "output_cost": 0.002,
      "total_cost": 0.003
    }
  }'
```

### Create Incident Tickets
```bash
curl -X POST http://localhost:8000/api/v1/incidents/tickets \
  -H "Content-Type: application/json" \
  -d '{
    "title": "High latency detected in OpenAI GPT-3.5",
    "description": "Average response time exceeded 2s threshold",
    "priority": "high",
    "category": "performance",
    "severity": "high",
    "affected_service": "openai-gpt-3.5",
    "metadata": {
      "metric_threshold": "2000ms",
      "current_value": "2850ms",
      "detection_time": "2024-01-15T10:30:00Z"
    }
  }'
```

### Query Cost Analytics
```bash
# Get cost summary for a project
curl "http://localhost:8000/api/v1/cost/summary?project_id=project_456&days=30"

# Get budget alerts
curl "http://localhost:8000/api/v1/cost/budget-alerts?project_id=project_456"

# Get cost breakdown by model
curl "http://localhost:8000/api/v1/cost/breakdown?group_by=model_name&days=7"
```

## ğŸ”§ Configuration

Create a `.env` file in the project root:

```env
# Application Settings
DEBUG=true
HOST=0.0.0.0
PORT=8000
SECRET_KEY=your-secret-key-change-in-production

# Database URLs
DATABASE_URL=postgresql://user:pass@localhost:5432/reskpoints
TIMESCALE_URL=postgresql://user:pass@localhost:5433/reskpoints_metrics
CLICKHOUSE_URL=http://localhost:8123
REDIS_URL=redis://localhost:6379/0

# External Integrations
ALERT_WEBHOOK_URL=https://hooks.slack.com/services/your/webhook/url

# Security & Auth
JWT_ALGORITHM=HS256
JWT_EXPIRE_MINUTES=60
RATE_LIMIT_REQUESTS=100

# Monitoring
PROMETHEUS_PORT=9090
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### Environment-Specific Configuration

<details>
<summary><b>Development</b></summary>

```env
DEBUG=true
LOG_LEVEL=DEBUG
DATABASE_URL=postgresql://postgres:password@localhost:5432/reskpoints_dev
REDIS_URL=redis://localhost:6379/1
```
</details>

<details>
<summary><b>Production</b></summary>

```env
DEBUG=false
LOG_LEVEL=INFO
DATABASE_URL=postgresql://user:secure_pass@prod-db:5432/reskpoints
TIMESCALE_URL=postgresql://user:secure_pass@timescale-prod:5432/metrics
CLICKHOUSE_URL=http://clickhouse-prod:8123
REDIS_URL=redis://redis-prod:6379/0
SECRET_KEY=production-secret-key-256-bit
```
</details>

## ğŸ“ˆ Monitoring & Observability

### Health Checks
- **Liveness**: `GET /live` - Basic application health
- **Readiness**: `GET /ready` - Service dependencies health
- **Detailed Health**: `GET /api/v1/health/` - Comprehensive system status

### Metrics Collection
ReskPoints exposes Prometheus metrics at `/metrics`:

```
# HELP reskpoints_requests_total Total HTTP requests
# TYPE reskpoints_requests_total counter
reskpoints_requests_total{method="POST",endpoint="/api/v1/metrics/submit"} 1250

# HELP reskpoints_request_duration_seconds Request duration
# TYPE reskpoints_request_duration_seconds histogram
reskpoints_request_duration_seconds_bucket{le="0.1"} 1100
```

### Pre-configured Dashboards
When using Docker Compose, Grafana includes:
- **API Performance**: Request rates, latencies, error rates
- **Cost Analytics**: Cost trends, budget tracking, optimization opportunities
- **System Health**: Database connections, cache hit rates, queue sizes
- **Business Metrics**: Token usage, model performance, user activity

## ğŸ› ï¸ Development

### Project Structure
```
reskpoints/
â”œâ”€â”€ api/                    # FastAPI routes and middleware
â”‚   â”œâ”€â”€ v1/                # API version 1 endpoints
â”‚   â”‚   â”œâ”€â”€ metrics.py     # Metrics collection endpoints
â”‚   â”‚   â”œâ”€â”€ cost.py        # Cost tracking endpoints
â”‚   â”‚   â”œâ”€â”€ incidents.py   # Incident management endpoints
â”‚   â”‚   â””â”€â”€ health.py      # Health check endpoints
â”‚   â””â”€â”€ middleware/        # Authentication, CORS, etc.
â”œâ”€â”€ core/                  # Core configuration and utilities
â”‚   â”œâ”€â”€ config.py         # Application settings
â”‚   â”œâ”€â”€ logging.py        # Structured logging setup
â”‚   â””â”€â”€ security.py       # Security utilities
â”œâ”€â”€ models/               # Pydantic data models
â”‚   â”œâ”€â”€ metrics.py        # AI metrics models
â”‚   â”œâ”€â”€ cost.py           # Cost tracking models
â”‚   â”œâ”€â”€ incident.py       # Incident management models
â”‚   â””â”€â”€ enums.py          # Shared enumerations
â”œâ”€â”€ services/             # Business logic layer
â”‚   â”œâ”€â”€ metrics/          # Metrics collection and analysis
â”‚   â”œâ”€â”€ cost/             # Cost calculation and optimization
â”‚   â”œâ”€â”€ incident/         # Incident management workflows
â”‚   â”œâ”€â”€ causality/        # Causality graph analysis
â”‚   â””â”€â”€ monitoring/       # System monitoring and alerting
â”œâ”€â”€ infrastructure/       # External integrations
â”‚   â”œâ”€â”€ database/         # Database connections and repositories
â”‚   â”œâ”€â”€ cache/            # Redis caching layer
â”‚   â””â”€â”€ external/         # External API integrations
â”œâ”€â”€ repositories/         # Data access layer
â””â”€â”€ utils/               # Shared utilities
```

### Running Tests
```bash
# Install development dependencies
pip install -e ".[dev,test]"

# Run all tests
pytest

# Run with coverage
pytest --cov=reskpoints --cov-report=html

# Run specific test categories
pytest tests/unit/          # Unit tests
pytest tests/integration/   # Integration tests
pytest -m "not slow"        # Skip slow tests
```

### Code Quality
```bash
# Format code
black reskpoints/ tests/
isort reskpoints/ tests/

# Lint code
flake8 reskpoints/ tests/
mypy reskpoints/

# Run all quality checks
pre-commit run --all-files
```

### Adding New Features

1. **Data Models**: Define Pydantic models in `models/`
2. **API Endpoints**: Add routes in `api/v1/`
3. **Business Logic**: Implement services in `services/`
4. **Data Access**: Create repositories in `repositories/`
5. **Tests**: Add tests in `tests/unit/` and `tests/integration/`

Example - Adding a new metric type:

```python
# models/metrics.py
class CustomMetric(AIMetric):
    custom_field: str
    additional_data: Dict[str, Any]

# api/v1/metrics.py
@router.post("/custom")
async def submit_custom_metric(metric: CustomMetric):
    return await metrics_service.process_custom_metric(metric)

# services/metrics/processor.py
async def process_custom_metric(self, metric: CustomMetric):
    # Business logic implementation
    pass
```

## ğŸš¢ Production Deployment

### Docker Production
```yaml
# docker-compose.prod.yml
version: '3.8'
services:
  reskpoints:
    image: reskpoints:latest
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=${DATABASE_URL}
      - REDIS_URL=${REDIS_URL}
      - SECRET_KEY=${SECRET_KEY}
    restart: unless-stopped
    depends_on:
      - postgres
      - redis
      - timescaledb
```

### Kubernetes Deployment
```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: reskpoints
spec:
  replicas: 3
  selector:
    matchLabels:
      app: reskpoints
  template:
    metadata:
      labels:
        app: reskpoints
    spec:
      containers:
      - name: reskpoints
        image: reskpoints:latest
        ports:
        - containerPort: 8000
        env:
        - name: DATABASE_URL
          valueFrom:
            secretKeyRef:
              name: reskpoints-secrets
              key: database-url
```

### Scaling Considerations

- **Horizontal Scaling**: Stateless application, scales with load balancers
- **Database**: Use read replicas for analytics queries
- **Cache**: Redis Cluster for high availability
- **Monitoring**: Distributed tracing with Jaeger for multi-instance deployments

## ğŸ”’ Security

### Authentication & Authorization
- **JWT Tokens**: Secure API access with configurable expiration
- **RBAC**: Role-based access control with granular permissions
- **API Keys**: Optional API key authentication for service-to-service

### Data Protection
- **Encryption**: Data encrypted at rest and in transit (TLS 1.3)
- **Input Validation**: Comprehensive request validation and sanitization
- **Audit Logging**: All sensitive operations logged for compliance

### Security Headers
```python
# Automatic security headers
Strict-Transport-Security: max-age=31536000; includeSubDomains
X-Content-Type-Options: nosniff
X-Frame-Options: DENY
X-XSS-Protection: 1; mode=block
```

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

### Quick Contribution Setup
```bash
# Fork the repository and clone
git clone https://github.com/yourusername/ReskPoints.git
cd ReskPoints

# Create a feature branch
git checkout -b feature/your-feature-name

# Setup development environment
./scripts/setup-dev.sh

# Make your changes and add tests
# ... develop ...

# Run quality checks
pre-commit run --all-files
pytest

# Commit and push
git commit -m "feat: add your feature description"
git push origin feature/your-feature-name
```

### Development Guidelines
- **Code Style**: Follow Black formatting and PEP 8
- **Testing**: Maintain >90% test coverage
- **Documentation**: Update docstrings and API documentation
- **Type Safety**: Use type hints for all new code

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— Links

- **Documentation**: [API Docs](http://localhost:8000/docs) (when running)
- **Repository**: [GitHub](https://github.com/Resk-Security/ReskPoints)
- **Issues**: [Bug Reports](https://github.com/Resk-Security/ReskPoints/issues)
- **Security**: [Security Policy](SECURITY.md)

## ğŸ¯ Roadmap

### Current Version (v0.1.0)
- âœ… Core API endpoints and data models
- âœ… Basic monitoring and health checks
- âœ… Docker development environment
- âœ… Authentication framework

### Next Release (v0.2.0)
- ğŸ”„ Database persistence layer
- ğŸ”„ Real-time anomaly detection
- ğŸ”„ Advanced cost analytics
- ğŸ”„ WebSocket real-time updates

### Future Releases
- ğŸ“‹ Machine learning-based insights
- ğŸ“‹ Advanced causality analysis
- ğŸ“‹ Multi-tenant architecture
- ğŸ“‹ Mobile application support

---

**Built with â¤ï¸ by Resk Security**

For questions or support, please [open an issue](https://github.com/Resk-Security/ReskPoints/issues) or contact us at contact@resk-security.com
